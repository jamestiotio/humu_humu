{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUTD 2021 50.007 Machine Learning HMM Project Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python38\\lib\\site-packages (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "# Setup and install dependencies\n",
    "!pip3 install numpy\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Enable floating-point underflow warning\n",
    "np.seterr(under=\"warn\")\n",
    "\n",
    "# Set OS-independent paths, relative to current directory\n",
    "es_train_path = os.path.join(\"data\", \"ES\", \"train\")\n",
    "es_dev_in_path = os.path.join(\"data\", \"ES\", \"dev.in\")\n",
    "es_dev_out_path = os.path.join(\"data\", \"ES\", \"dev.out\")\n",
    "es_dev_p1_out_path = os.path.join(\"data\", \"ES\", \"dev.p1.out\")\n",
    "ru_train_path = os.path.join(\"data\", \"RU\", \"train\")\n",
    "ru_dev_in_path = os.path.join(\"data\", \"RU\", \"dev.in\")\n",
    "ru_dev_out_path = os.path.join(\"data\", \"RU\", \"dev.out\")\n",
    "ru_dev_p1_out_path = os.path.join(\"data\", \"RU\", \"dev.p1.out\")\n",
    "\n",
    "# Define constant variables\n",
    "N = 7\n",
    "START, O, BPOS, IPOS, BNEU, INEU, BNEG, INEG, END = 0, 1, 2, 3, 4, 5, 6, 7, 8\n",
    "labels = {\"START\": START,\n",
    "          \"O\": O,\n",
    "          \"B-positive\": BPOS,\n",
    "          \"I-positive\": IPOS,\n",
    "          \"B-neutral\": BNEU,\n",
    "          \"I-neutral\": INEU,\n",
    "          \"B-negative\": BNEG,\n",
    "          \"I-negative\": INEG,\n",
    "          \"END\": END}\n",
    "labels_list = [\"START\", \"O\", \"B-positive\", \"I-positive\", \"B-neutral\", \"I-neutral\", \"B-negative\", \"I-negative\", \"END\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dev.in data\n",
    "def read_dev_in_data(filepath):\n",
    "    results = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            results.append(line.strip())\n",
    "    return results\n",
    "\n",
    "# Read dev.out data\n",
    "def read_dev_out_data(filepath):\n",
    "    results = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if len(line.strip().rsplit(\" \", 1)) == 2:\n",
    "                token, label = line.strip().rsplit(\" \", 1)\n",
    "                results.append((token, labels[label]))\n",
    "            else:\n",
    "                continue\n",
    "    return results\n",
    "\n",
    "# Read training data\n",
    "def read_training_data(filepath):\n",
    "    results = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if len(line.strip().rsplit(\" \", 1)) == 2:\n",
    "                token, label = line.strip().rsplit(\" \", 1)\n",
    "                results.append((token.lower(), labels[label]))\n",
    "            else:\n",
    "                continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_of_labels(input_data):\n",
    "    return Counter(elem[1] for elem in input_data)\n",
    "\n",
    "def get_all_unique_tokens(input_data):\n",
    "    # Ensure that this order stays consistent between runs\n",
    "    return list(set(item[0] for item in input_data))\n",
    "\n",
    "# For the return value, we follow the matrix format defined in the slides accordingly\n",
    "def calculate_emission_parameters(input_data, all_unique_tokens):\n",
    "    k = 1.0\n",
    "    # Final index is for #UNK# tokens\n",
    "    emission_counts = np.zeros((N, len(all_unique_tokens) + 1), dtype=np.longdouble)\n",
    "\n",
    "    label_counts = np.array(list(val[1] for val in sorted(calculate_number_of_labels(input_data).items())))\n",
    "\n",
    "    for token, label in input_data:\n",
    "        emission_counts[label - 1][all_unique_tokens.index(token)] += 1\n",
    "\n",
    "    # This is for the other case of #UNK# tokens\n",
    "    emission_counts[:, -1] = np.full((1, N), k)[0]\n",
    "\n",
    "    emission_parameters = np.empty((N, len(all_unique_tokens) + 1), dtype=np.longdouble)\n",
    "\n",
    "    for index, _ in enumerate(emission_counts):\n",
    "        emission_parameters[index] = emission_counts[index] / (label_counts[index] + k)\n",
    "\n",
    "    # Do some assertion checks\n",
    "    for row in emission_parameters:\n",
    "        assert np.absolute(1.0 - np.sum(row)) < np.finfo(np.longdouble).eps\n",
    "\n",
    "    return emission_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tag from word\n",
    "def get_label_from_token(input_word, all_unique_tokens, emission_parameters):\n",
    "    if input_word not in all_unique_tokens:\n",
    "        return labels_list[np.argmax(emission_parameters[:, -1]) + 1]\n",
    "\n",
    "    else:\n",
    "        return labels_list[np.argmax(emission_parameters[:, all_unique_tokens.index(input_word)]) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_prediction_output_to_file(language):\n",
    "    if language == \"ES\":\n",
    "        # Conduct training/supervised learning (M-Step)\n",
    "        train_data = read_training_data(es_train_path)\n",
    "        all_unique_tokens = get_all_unique_tokens(train_data)\n",
    "        emission_parameters = calculate_emission_parameters(train_data, all_unique_tokens)\n",
    "\n",
    "        # Execute testing/decoding (E-Step)\n",
    "        predicted_results = []\n",
    "        test_data = read_dev_in_data(es_dev_in_path)\n",
    "        for token in test_data:\n",
    "            if token:\n",
    "                predicted_results.append(token + \" \" + get_label_from_token(token.lower(), all_unique_tokens, emission_parameters))\n",
    "            else:\n",
    "                predicted_results.append(\"\")\n",
    "        with open(es_dev_p1_out_path, \"w+\", encoding=\"utf-8\") as file:\n",
    "            for line in predicted_results:\n",
    "                file.write(line + \"\\n\")\n",
    "\n",
    "    elif language == \"RU\":\n",
    "        # Conduct training/supervised learning (M-Step)\n",
    "        train_data = read_training_data(ru_train_path)\n",
    "        all_unique_tokens = get_all_unique_tokens(train_data)\n",
    "        emission_parameters = calculate_emission_parameters(train_data, all_unique_tokens)\n",
    "\n",
    "        # Execute testing/decoding (E-Step)\n",
    "        predicted_results = []\n",
    "        test_data = read_dev_in_data(ru_dev_in_path)\n",
    "        for token in test_data:\n",
    "            if token:\n",
    "                predicted_results.append(token + \" \" + get_label_from_token(token.lower(), all_unique_tokens, emission_parameters))\n",
    "            else:\n",
    "                predicted_results.append(\"\")\n",
    "        with open(ru_dev_p1_out_path, \"w+\", encoding=\"utf-8\") as file:\n",
    "            for line in predicted_results:\n",
    "                file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in [\"ES\", \"RU\"]:\n",
    "    write_prediction_output_to_file(language)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
